{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khenm/object_detection_yolo_model/blob/develop/helmet_safety_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helmet Safety Detection\n",
        "The process of detecting helmet consists two major steps: loading the dataset and pretrained model, and training (fine-tuning).\\\n",
        "First, we have to download the dataset of helmet safety for later training process (Step 1.1), then, unzip and store it to the folder content. Also, we have to import pre-trained model YOLOv10 by cloning from github (Step 2.1). The model we use is the nano (n) version (yolov10n.pt), as it is easier to handle the weights."
      ],
      "metadata": {
        "id": "_J3R_lKOMJRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I. Loading dataset"
      ],
      "metadata": {
        "id": "IndSrTiFNOgl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGMUxIJcbSdr"
      },
      "outputs": [],
      "source": [
        "# Step 1.1 -- Download the data for Helmet Safety\n",
        "!gdown '1twdtZEfcw4ghSZIiPDypJurZnNXzMO7R'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1.2 -- Unzip the folder\n",
        "!mkdir safety_helmet_dataset\n",
        "!unzip -q '/content/Safety_Helmet_Dataset.zip' -d '/content/safety_helmet_dataset'"
      ],
      "metadata": {
        "id": "tk-oh51YbgHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading pre-trained model"
      ],
      "metadata": {
        "id": "vmwyhRETNQU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2.1 -- Clone yolov10\n",
        "!git clone https://github.com/THU-MIG/yolov10.git\n",
        "%cd yolov10"
      ],
      "metadata": {
        "id": "Ksrl5R-abi0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2.2 -- Install requirements\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -e ."
      ],
      "metadata": {
        "collapsed": true,
        "id": "tHTPV18OblrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2.3 -- Load model YOLOv10\n",
        "!wget https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt"
      ],
      "metadata": {
        "id": "6mYESrKwbndE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2.4 -- Load model YOLOv10\n",
        "from ultralytics import YOLOv10\n",
        "\n",
        "MODEL_PATH = 'yolov10n.pt'\n",
        "model = YOLOv10(MODEL_PATH)"
      ],
      "metadata": {
        "id": "Wm_4RqO7ctXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " II. Fine - tuning"
      ],
      "metadata": {
        "id": "8SH2t6bXNuls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 -- Training the dataset\n",
        "YAML_PATH = '../safety_helmet_dataset/data.yaml'\n",
        "EPOCHS = 50\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 64 # by default, better go 256 if your gpu can handle it.\n",
        "\n",
        "model.train(data=YAML_PATH, epochs=EPOCHS, batch=BATCH_SIZE, imgsz=IMG_SIZE)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o5Qudz-ecwE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "III. Trained data and samples"
      ],
      "metadata": {
        "id": "QOlM9UmrOGk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINED_MODEL_PATH = 'runs/detect/train/weights/best.pt'\n",
        "model = YOLOv10(TRAINED_MODEL_PATH)\n",
        "\n",
        "model.val(data=YAML_PATH, imgsz=IMG_SIZE, split='test')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HC58-E328Gaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# showing samples\n",
        "IMG_PATH = '/content/safety_helmet_dataset/train/images/helmet-113-_jpg.rf.224e4c979640131b66a548756f8a6396.jpg'\n",
        "result = model(source=IMG_PATH)[0]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(result.plot())"
      ],
      "metadata": {
        "id": "LVWQt675OLgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}